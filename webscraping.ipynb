{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Navigated to the page. Waiting for it to load...\n",
      "Found 3 iframes on the page.\n",
      "Switched to iframe 1.\n",
      "Vaadin grid found.\n",
      "Found headers: ['Name', 'Street1', 'City', 'County', 'Phone']\n",
      "Starting data extraction...\n",
      "Estimated row count: 1671\n",
      "Fetching rows 0 to 50...\n",
      "Collected 58 unique rows so far\n",
      "Fetching rows 50 to 100...\n",
      "Collected 108 unique rows so far\n",
      "Fetching rows 100 to 150...\n",
      "Collected 158 unique rows so far\n",
      "Fetching rows 150 to 200...\n",
      "Collected 208 unique rows so far\n",
      "Fetching rows 200 to 250...\n",
      "Collected 258 unique rows so far\n",
      "Fetching rows 250 to 300...\n",
      "Collected 308 unique rows so far\n",
      "Fetching rows 300 to 350...\n",
      "Collected 358 unique rows so far\n",
      "Fetching rows 350 to 400...\n",
      "Collected 408 unique rows so far\n",
      "Fetching rows 400 to 450...\n",
      "Collected 458 unique rows so far\n",
      "Fetching rows 450 to 500...\n",
      "Collected 508 unique rows so far\n",
      "Fetching rows 500 to 550...\n",
      "Collected 558 unique rows so far\n",
      "Fetching rows 550 to 600...\n",
      "Collected 608 unique rows so far\n",
      "Fetching rows 600 to 650...\n",
      "Collected 658 unique rows so far\n",
      "Fetching rows 650 to 700...\n",
      "Collected 708 unique rows so far\n",
      "Fetching rows 700 to 750...\n",
      "Collected 757 unique rows so far\n",
      "Fetching rows 750 to 800...\n",
      "Collected 808 unique rows so far\n",
      "Fetching rows 800 to 850...\n",
      "Collected 858 unique rows so far\n",
      "Fetching rows 850 to 900...\n",
      "Collected 909 unique rows so far\n",
      "Fetching rows 900 to 950...\n",
      "Collected 958 unique rows so far\n",
      "Fetching rows 950 to 1000...\n",
      "Collected 1008 unique rows so far\n",
      "Fetching rows 1000 to 1050...\n",
      "Collected 1058 unique rows so far\n",
      "Fetching rows 1050 to 1100...\n",
      "Collected 1108 unique rows so far\n",
      "Fetching rows 1100 to 1150...\n",
      "Collected 1158 unique rows so far\n",
      "Fetching rows 1150 to 1200...\n",
      "Collected 1208 unique rows so far\n",
      "Fetching rows 1200 to 1250...\n",
      "Collected 1258 unique rows so far\n",
      "Fetching rows 1250 to 1300...\n",
      "Collected 1308 unique rows so far\n",
      "Fetching rows 1300 to 1350...\n",
      "Collected 1358 unique rows so far\n",
      "Fetching rows 1350 to 1400...\n",
      "Collected 1408 unique rows so far\n",
      "Fetching rows 1400 to 1450...\n",
      "Collected 1458 unique rows so far\n",
      "Fetching rows 1450 to 1500...\n",
      "Collected 1508 unique rows so far\n",
      "Fetching rows 1500 to 1550...\n",
      "Collected 1556 unique rows so far\n",
      "Fetching rows 1550 to 1600...\n",
      "Collected 1605 unique rows so far\n",
      "Fetching rows 1600 to 1650...\n",
      "Collected 1653 unique rows so far\n",
      "Fetching rows 1650 to 1700...\n",
      "Collected 1659 unique rows so far\n",
      "Fetching rows 1700 to 1750...\n",
      "Collected 1659 unique rows so far\n",
      "Fetching rows 1750 to 1800...\n",
      "Collected 1659 unique rows so far\n",
      "Fetching rows 1800 to 1850...\n",
      "Error processing chunk starting at 1800: HTTPConnectionPool(host='localhost', port=54769): Read timed out. (read timeout=120)\n",
      "Already collected significant data, stopping due to errors\n",
      "Extraction complete. Found 1659 unique items.\n",
      "Data validation: DataFrame shape: (1659, 5)\n",
      "Data saved to vaccination_clinics_complete.csv\n",
      "\n",
      "Sample data:\n",
      "                                City                               County  \\\n",
      "0  CitySort ascendingSort descending  CountySort ascendingSort descending   \n",
      "1                          Stuttgart                             Arkansas   \n",
      "2                              Wynne                                Cross   \n",
      "3                             Manila                          Mississippi   \n",
      "4                      Fairfield Bay                            Van Buren   \n",
      "\n",
      "                                                Name  \\\n",
      "0                  NameSort ascendingSort descending   \n",
      "1  Bethea Brothers Drug Company Inc. (Coker Hampton)   \n",
      "2                                  Caldwell Pharmacy   \n",
      "3                                   Delta Drug, Inc.   \n",
      "4                             Fairfield Bay Pharmacy   \n",
      "\n",
      "                                Phone                               Street1  \n",
      "0  PhoneSort ascendingSort descending  Street1Sort ascendingSort descending  \n",
      "1                        870-673-2691                 218 South Main Street  \n",
      "2                        870-238-7085             804 South Falls Boulevard  \n",
      "3                        870-561-3113                  257 S. Hwy 18 Bypass  \n",
      "4                        501-884-3388                367 Dave Creek Parkway  \n",
      "Saved 1659 rows to vaccination_clinics_partial.csv before quitting\n",
      "Saved raw data to vaccination_clinics_raw.json as backup\n",
      "Closing the browser...\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.edge.service import Service\n",
    "from selenium.webdriver.edge.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import pandas as pd\n",
    "import time\n",
    "import json\n",
    "\n",
    "# Setup Edge WebDriver with optimized settings\n",
    "edge_options = Options()\n",
    "edge_options.add_argument(\"--window-size=1920,1080\")\n",
    "edge_options.add_argument(\"--disable-extensions\")  # Disable extensions to improve performance\n",
    "edge_options.add_argument(\"--disable-gpu\")  # Disable GPU hardware acceleration\n",
    "edge_options.add_argument(\"--disable-dev-shm-usage\")  # Overcome limited resource issues\n",
    "edge_options.add_argument(\"--no-sandbox\")  # Bypass OS security model\n",
    "edge_options.page_load_strategy = 'normal'  # Wait for full page load\n",
    "\n",
    "service = Service(\"C:/Users/Alex/Downloads/edgedriver_win64 (1)/msedgedriver.exe\")\n",
    "driver = webdriver.Edge(service=service, options=edge_options)\n",
    "\n",
    "try:\n",
    "    # Navigate to the page\n",
    "    driver.get(\"https://healthy.arkansas.gov/programs-services/diseases-conditions/covid-19/covid-19-vaccines/covid-19-vaccination-clinics-locations/\")\n",
    "    print(\"Navigated to the page. Waiting for it to load...\")\n",
    "    \n",
    "    # Wait for iframes to be present\n",
    "    WebDriverWait(driver, 20).until(\n",
    "        EC.presence_of_element_located((By.TAG_NAME, \"iframe\"))\n",
    "    )\n",
    "    \n",
    "    # Find iframes\n",
    "    iframes = driver.find_elements(By.TAG_NAME, \"iframe\")\n",
    "    print(f\"Found {len(iframes)} iframes on the page.\")\n",
    "    \n",
    "    # Switch to the first iframe\n",
    "    driver.switch_to.frame(iframes[0])\n",
    "    print(\"Switched to iframe 1.\")\n",
    "    \n",
    "    # Wait for the Vaadin grid to load\n",
    "    WebDriverWait(driver, 20).until(\n",
    "        EC.presence_of_element_located((By.TAG_NAME, \"vaadin-grid\"))\n",
    "    )\n",
    "    print(\"Vaadin grid found.\")\n",
    "    \n",
    "    # Extract headers\n",
    "    headers = []\n",
    "    try:\n",
    "        header_elements = WebDriverWait(driver, 20).until(\n",
    "            EC.presence_of_all_elements_located((By.CSS_SELECTOR, \"vaadin-grid-sorter\"))\n",
    "        )\n",
    "        headers = [header.text.strip() for header in header_elements if header.text.strip()]\n",
    "        print(f\"Found headers: {headers}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error getting headers: {e}\")\n",
    "    \n",
    "    # Modified JavaScript specifically for Vaadin grid scrolling and extraction\n",
    "    js_script = \"\"\"\n",
    "    return (async function() {\n",
    "        const grid = document.querySelector('vaadin-grid');\n",
    "        if (!grid) return { error: \"Grid not found\" };\n",
    "        \n",
    "        // Function to safely extract current visible data\n",
    "        function extractVisibleData() {\n",
    "            const headers = Array.from(document.querySelectorAll('vaadin-grid-sorter'))\n",
    "                .map(h => h.textContent.trim())\n",
    "                .filter(h => h); // Filter out empty headers\n",
    "                \n",
    "            if (headers.length === 0) {\n",
    "                return { error: \"No headers found\" };\n",
    "            }\n",
    "            \n",
    "            const numCols = headers.length;\n",
    "            const allCells = Array.from(document.querySelectorAll('vaadin-grid-cell-content'));\n",
    "            let rows = [];\n",
    "            \n",
    "            // Process cells into rows\n",
    "            for (let i = 0; i < allCells.length; i += numCols) {\n",
    "                if (i + numCols <= allCells.length) {\n",
    "                    let row = {};\n",
    "                    let hasContent = false;\n",
    "                    \n",
    "                    for (let j = 0; j < numCols; j++) {\n",
    "                        const cellContent = allCells[i + j].textContent.trim();\n",
    "                        row[headers[j] || `Column${j+1}`] = cellContent;\n",
    "                        if (cellContent) hasContent = true;\n",
    "                    }\n",
    "                    \n",
    "                    // Only add non-empty rows\n",
    "                    if (hasContent) {\n",
    "                        rows.push(row);\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            return rows;\n",
    "        }\n",
    "        \n",
    "        // Get an estimate of total rows to scroll\n",
    "        function getEstimatedRowCount() {\n",
    "            // Try to get row count from Vaadin grid properties\n",
    "            if (grid._effectiveSize) return grid._effectiveSize;\n",
    "            if (grid.size) return grid.size;\n",
    "            \n",
    "            // If no properties available, make an educated guess\n",
    "            // based on the visible rows and assuming more are available\n",
    "            return 500; // Default to a reasonably large number\n",
    "        }\n",
    "        \n",
    "        // Use Vaadin grid's native scrollToIndex method with progressive loading\n",
    "        async function progressiveScroll() {\n",
    "            let allData = [];\n",
    "            let lastDataLength = -1;\n",
    "            let seenDataStrings = new Set();\n",
    "            const totalRows = getEstimatedRowCount();\n",
    "            const batchSize = 20; // How many rows to jump each time\n",
    "            \n",
    "            console.log(`Starting to scroll through approximately ${totalRows} rows`);\n",
    "            \n",
    "            // Initial data extraction\n",
    "            let currentData = extractVisibleData();\n",
    "            if (Array.isArray(currentData)) {\n",
    "                currentData.forEach(row => {\n",
    "                    const rowStr = JSON.stringify(row);\n",
    "                    if (!seenDataStrings.has(rowStr)) {\n",
    "                        seenDataStrings.add(rowStr);\n",
    "                        allData.push(row);\n",
    "                    }\n",
    "                });\n",
    "            }\n",
    "            \n",
    "            // Scroll through the grid in batches\n",
    "            for (let index = 0; index < totalRows; index += batchSize) {\n",
    "                try {\n",
    "                    // Use the grid's native scrollToIndex method\n",
    "                    grid.scrollToIndex(index);\n",
    "                    \n",
    "                    // Wait for rendering\n",
    "                    await new Promise(resolve => setTimeout(resolve, 300));\n",
    "                    \n",
    "                    // Extract data from current view\n",
    "                    currentData = extractVisibleData();\n",
    "                    if (Array.isArray(currentData)) {\n",
    "                        let newRowsAdded = 0;\n",
    "                        \n",
    "                        currentData.forEach(row => {\n",
    "                            const rowStr = JSON.stringify(row);\n",
    "                            if (!seenDataStrings.has(rowStr)) {\n",
    "                                seenDataStrings.add(rowStr);\n",
    "                                allData.push(row);\n",
    "                                newRowsAdded++;\n",
    "                            }\n",
    "                        });\n",
    "                        \n",
    "                        console.log(`Scrolled to index ${index}, collected ${allData.length} total rows, added ${newRowsAdded} new rows`);\n",
    "                        \n",
    "                        // If we've scrolled several times without getting new data, we might be at the end\n",
    "                        if (newRowsAdded === 0 && index > 100) {\n",
    "                            const additionalAttempts = 3;\n",
    "                            let foundNewData = false;\n",
    "                            \n",
    "                            // Make a few more attempts at larger scroll increments\n",
    "                            for (let j = 1; j <= additionalAttempts; j++) {\n",
    "                                grid.scrollToIndex(index + j * batchSize * 2);\n",
    "                                await new Promise(resolve => setTimeout(resolve, 500));\n",
    "                                \n",
    "                                const moreData = extractVisibleData();\n",
    "                                if (Array.isArray(moreData)) {\n",
    "                                    let moreNewRows = 0;\n",
    "                                    \n",
    "                                    moreData.forEach(row => {\n",
    "                                        const rowStr = JSON.stringify(row);\n",
    "                                        if (!seenDataStrings.has(rowStr)) {\n",
    "                                            seenDataStrings.add(rowStr);\n",
    "                                            allData.push(row);\n",
    "                                            moreNewRows++;\n",
    "                                            foundNewData = true;\n",
    "                                        }\n",
    "                                    });\n",
    "                                    \n",
    "                                    console.log(`Additional attempt ${j}: added ${moreNewRows} more rows`);\n",
    "                                }\n",
    "                            }\n",
    "                            \n",
    "                            if (!foundNewData) {\n",
    "                                console.log(\"No new data found after multiple attempts. Assuming we've reached the end.\");\n",
    "                                break;\n",
    "                            }\n",
    "                        }\n",
    "                    }\n",
    "                } catch (error) {\n",
    "                    console.log(`Error during scrolling at index ${index}: ${error.message}`);\n",
    "                    // If we hit an error, try a few more times with larger jumps\n",
    "                    try {\n",
    "                        grid.scrollToIndex(index + batchSize * 3);\n",
    "                        await new Promise(resolve => setTimeout(resolve, 500));\n",
    "                    } catch (finalError) {\n",
    "                        console.log(\"Failed additional scroll attempt. Collecting what we have so far.\");\n",
    "                        break;\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            // Make one final attempt to scroll to the absolute bottom\n",
    "            try {\n",
    "                // Scroll to a very large index to try to reach the bottom\n",
    "                grid.scrollToIndex(totalRows * 2);\n",
    "                await new Promise(resolve => setTimeout(resolve, 1000));\n",
    "                \n",
    "                // Get any final rows\n",
    "                currentData = extractVisibleData();\n",
    "                if (Array.isArray(currentData)) {\n",
    "                    currentData.forEach(row => {\n",
    "                        const rowStr = JSON.stringify(row);\n",
    "                        if (!seenDataStrings.has(rowStr)) {\n",
    "                            seenDataStrings.add(rowStr);\n",
    "                            allData.push(row);\n",
    "                        }\n",
    "                    });\n",
    "                }\n",
    "            } catch (error) {\n",
    "                console.log(\"Error during final scroll attempt: \" + error.message);\n",
    "            }\n",
    "            \n",
    "            console.log(`Scrolling complete. Collected ${allData.length} total unique rows.`);\n",
    "            return allData;\n",
    "        }\n",
    "        \n",
    "        // Execute the scrolling strategy and return the data\n",
    "        return await progressiveScroll();\n",
    "    })();\n",
    "    \"\"\"\n",
    "    \n",
    "    # Set script timeout to a higher value\n",
    "    driver.set_script_timeout(300)  # 5 minutes timeout for scripts\n",
    "    \n",
    "    # Execute the JavaScript with a more reliable approach - collect data in chunks\n",
    "    print(\"Starting data extraction...\")\n",
    "    \n",
    "    # First approach: Get total row count if possible\n",
    "    try:\n",
    "        row_count_script = \"\"\"\n",
    "        const grid = document.querySelector('vaadin-grid');\n",
    "        if (!grid) return 0;\n",
    "        if (grid._effectiveSize) return grid._effectiveSize;\n",
    "        if (grid.size) return grid.size;\n",
    "        return 500; // default estimate\n",
    "        \"\"\"\n",
    "        estimated_rows = driver.execute_script(row_count_script)\n",
    "        print(f\"Estimated row count: {estimated_rows}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error estimating row count: {e}\")\n",
    "        estimated_rows = 500\n",
    "    \n",
    "    # Use a chunked approach to avoid timeouts\n",
    "    chunk_size = 50\n",
    "    total_data = []\n",
    "    seen_rows = set()\n",
    "    \n",
    "    for start_idx in range(0, estimated_rows * 2, chunk_size):\n",
    "        try:\n",
    "            chunk_script = f\"\"\"\n",
    "            return (async function() {{\n",
    "                const grid = document.querySelector('vaadin-grid');\n",
    "                if (!grid) return {{ error: \"Grid not found\" }};\n",
    "                \n",
    "                // Function to extract visible data\n",
    "                function extractVisibleData() {{\n",
    "                    const headers = Array.from(document.querySelectorAll('vaadin-grid-sorter'))\n",
    "                        .map(h => h.textContent.trim())\n",
    "                        .filter(h => h);\n",
    "                    \n",
    "                    if (headers.length === 0) return [];\n",
    "                    \n",
    "                    const numCols = headers.length;\n",
    "                    const allCells = Array.from(document.querySelectorAll('vaadin-grid-cell-content'));\n",
    "                    let rows = [];\n",
    "                    \n",
    "                    for (let i = 0; i < allCells.length; i += numCols) {{\n",
    "                        if (i + numCols <= allCells.length) {{\n",
    "                            let row = {{}};\n",
    "                            let hasContent = false;\n",
    "                            \n",
    "                            for (let j = 0; j < numCols; j++) {{\n",
    "                                const cellContent = allCells[i + j].textContent.trim();\n",
    "                                row[headers[j] || `Column${{j+1}}`] = cellContent;\n",
    "                                if (cellContent) hasContent = true;\n",
    "                            }}\n",
    "                            \n",
    "                            if (hasContent) rows.push(row);\n",
    "                        }}\n",
    "                    }}\n",
    "                    \n",
    "                    return rows;\n",
    "                }}\n",
    "                \n",
    "                // Scroll to chunk start\n",
    "                try {{\n",
    "                    grid.scrollToIndex({start_idx});\n",
    "                    await new Promise(resolve => setTimeout(resolve, 500));\n",
    "                    \n",
    "                    // Scroll through this chunk\n",
    "                    let allData = [];\n",
    "                    for (let i = 0; i < {chunk_size}; i++) {{\n",
    "                        grid.scrollToIndex({start_idx} + i);\n",
    "                        await new Promise(resolve => setTimeout(resolve, 100));\n",
    "                        \n",
    "                        const data = extractVisibleData();\n",
    "                        if (data && data.length > 0) {{\n",
    "                            allData = [...allData, ...data];\n",
    "                        }}\n",
    "                    }}\n",
    "                    \n",
    "                    return allData;\n",
    "                }} catch (e) {{\n",
    "                    return {{ error: e.toString() }};\n",
    "                }}\n",
    "            }})();\n",
    "            \"\"\"\n",
    "            \n",
    "            print(f\"Fetching rows {start_idx} to {start_idx + chunk_size}...\")\n",
    "            chunk_data = driver.execute_script(chunk_script)\n",
    "            \n",
    "            if isinstance(chunk_data, list):\n",
    "                # Add only unique rows to our total dataset\n",
    "                for row in chunk_data:\n",
    "                    row_hash = str(sorted([(k, v) for k, v in row.items()]))\n",
    "                    if row_hash not in seen_rows:\n",
    "                        seen_rows.add(row_hash)\n",
    "                        total_data.append(row)\n",
    "                \n",
    "                print(f\"Collected {len(total_data)} unique rows so far\")\n",
    "                \n",
    "                # If we didn't get any new rows in multiple consecutive chunks, we might be done\n",
    "                if len(chunk_data) == 0 and start_idx > estimated_rows:\n",
    "                    print(\"No more data found, likely reached the end\")\n",
    "                    break\n",
    "                \n",
    "            elif isinstance(chunk_data, dict) and 'error' in chunk_data:\n",
    "                print(f\"Error in chunk: {chunk_data['error']}\")\n",
    "                # Try to continue with the next chunk\n",
    "            else:\n",
    "                print(f\"Unexpected data format in chunk: {type(chunk_data)}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing chunk starting at {start_idx}: {e}\")\n",
    "            # Let's try a few more chunks before giving up completely\n",
    "            if start_idx > estimated_rows:\n",
    "                print(\"Already collected significant data, stopping due to errors\")\n",
    "                break\n",
    "    \n",
    "    all_data = total_data\n",
    "    print(f\"Extraction complete. Found {len(all_data)} unique items.\")\n",
    "    \n",
    "    # Convert to DataFrame and save\n",
    "    if all_data and isinstance(all_data, list) and len(all_data) > 0:\n",
    "        # Remove duplicates (as a safeguard)\n",
    "        df = pd.DataFrame(all_data).drop_duplicates()\n",
    "        \n",
    "        # Data validation\n",
    "        print(f\"Data validation: DataFrame shape: {df.shape}\")\n",
    "        \n",
    "        # Save to CSV\n",
    "        csv_filename = \"vaccination_clinics_complete.csv\"\n",
    "        df.to_csv(csv_filename, index=False)\n",
    "        print(f\"Data saved to {csv_filename}\")\n",
    "        print(\"\\nSample data:\")\n",
    "        print(df.head())\n",
    "    elif isinstance(all_data, dict) and 'error' in all_data:\n",
    "        print(f\"Error in JavaScript execution: {all_data['error']}\")\n",
    "    else:\n",
    "        print(\"Failed to extract data or no data found.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {str(e)}\")\n",
    "\n",
    "finally:\n",
    "    # Even if we had an exception, try to save whatever data we collected\n",
    "    if 'all_data' in locals() and isinstance(all_data, list) and len(all_data) > 0:\n",
    "        try:\n",
    "            # Save to CSV\n",
    "            csv_filename = \"vaccination_clinics_partial.csv\"\n",
    "            pdf = pd.DataFrame(all_data).drop_duplicates()\n",
    "            pdf.to_csv(csv_filename, index=False)\n",
    "            print(f\"Saved {len(pdf)} rows to {csv_filename} before quitting\")\n",
    "            \n",
    "            # Also save raw JSON as backup\n",
    "            with open(\"vaccination_clinics_raw.json\", \"w\") as f:\n",
    "                json.dump(all_data, f)\n",
    "                print(\"Saved raw data to vaccination_clinics_raw.json as backup\")\n",
    "        except Exception as save_error:\n",
    "            print(f\"Error saving partial data: {save_error}\")\n",
    "    \n",
    "    # Close the driver\n",
    "    print(\"Closing the browser...\")\n",
    "    driver.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
